---
title: What Makes Frisbee Better?
order: 0
---

With **Zero Allocations** in the hot-path and an 8-Byte Packet Header, the network overhead of Frisbee is significantly
lower than that of existing protocols like GRPC (performance comparisons available in our [Performance Section](https://frisbee.sh/performance/introduction))
which use HTTP/2 under the hood.

We originally designed Frisbee for our own messaging needs at [Loophole Labs](https://loopholelabs.io), where we needed
to send both large and small amounts of data in a latency-sensitive manner. We also needed it to be massively scalable,
able to handle thousands of concurrent connections and able to send millions of messages.

To fulfill these requirements we spent a lot of time architecting the Frisbee data path to be extremely fast and extremely efficient.

Our optimizations began with the <CH.InlineCode>Packet</CH.InlineCode> package, which efficiently recycles the byte buffers
that are used throughout Frisbee to hold interstitial data. On top of this, we built our custom <CH.InlineCode>Encoding</CH.InlineCode>
and <CH.InlineCode>Decoding</CH.InlineCode> packages, which read and write directly from the <CH.InlineCode>Packet.packet</CH.InlineCode>
structure. By recycling the <CH.InlineCode>Packet.packet</CH.InlineCode> structures throughout Frisbee, we can significantly reduce
the number of allocations in the encoding and decoding functions.

Most of our other optimizations center around our network I/O. Actually reading and writing data from a TCP socket
is extremely slow, and so Frisbee makes an effort to maximize the amount of data that we read or write to a TCP socket
while avoiding any additional latency.

All these optimizations - as well as Frisbee's architecture, make it feasible to use Frisbee (as well as [Frisbee RPC]())
in both latency-sensitive applications like in real-time streaming, as well as data-heavy applications like PUB/SUB systems.

# Why TCP?

Many of the recently released wire protocols like [Wireguard](https://www.wireguard.com/) and [QUIC](https://datatracker.ietf.org/doc/html/rfc9000)
use UDP under the hood instead of TCP. Unlike TCP, UDP is an unreliable transport mechanism and provides no guarantees
on packet delivery.

There are benefits to using UDP and implementing packet delivery mechanisms on top of it - QUIC, for example, uses
UDP to solve the [head-of-line blocking](https://calendar.perfplanet.com/2020/head-of-line-blocking-in-quic-and-http-3-the-details/)
problem.

For Frisbee, however, we wanted to make use of the existing performance optimizations that networking software and hardware
have for TCP traffic, and we wanted the strong guarantees around packet delivery that TCP already provides.

# Unique Features

There are a number of exciting features built into Frisbee that allow it to be as extendable and flexible as it is.

One of those features is the ability for your application to **turn Frisbee off** whenever you like. This means it's possible to establish a
Frisbee connection, stream some data over it (or use RPCs), and then turn Frisbee off and retrieve a complete normal TCP socket with zero overhead.

This opens up a world of interesting messaging patterns that simply aren't possible with other frameworks and protocol -
like authenticating a connection using Frisbee RPC then turning Frisbee off and using the resulting TCP socket to proxy HTTP traffic.

Frisbee is also designed to deviate from the standard client-server model, where the client sends a request and receives
a response. Instead, Frisbee makes it possible for either the client or the server to send requests once a connection
is established. Within Frisbee, we refer to the <CH.InlineCode>Server</CH.InlineCode> as the component that the <CH.InlineCode>Client</CH.InlineCode>
initiates a connection to. After the connection itself is established, the messaging pattern is completely up to the developer.
